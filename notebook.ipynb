{"cells":[{"cell_type":"markdown","id":"35aebf2e-0635-4fef-bc9a-877b6a20fb13","metadata":{},"source":["### The Data\n","\n","The data is a small subset of the Credit Card Approval dataset from the UCI Machine Learning Repository showing the credit card applications a bank receives. This dataset has been loaded as a `pandas` DataFrame called `cc_apps`. The last column in the dataset is the target value."]},{"cell_type":"code","execution_count":44,"id":"6e86b1e8-a3fa-4b09-982f-795f218bd1a6","metadata":{"executionCancelledAt":null,"executionTime":1898,"lastExecutedAt":1713963817980,"lastExecutedByKernel":"4ee93555-5ef3-4306-9940-0d4b1932ee53","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\n\n# Load the dataset\ncc_apps = pd.read_csv(\"cc_approvals.data\", header=None) \ncc_apps.head()","outputsMetadata":{"0":{"height":185,"type":"dataFrame"}}},"outputs":[],"source":["# Import necessary libraries\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, cross_val_score, KFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.metrics import classification_report, confusion_matrix"]},{"cell_type":"code","execution_count":2,"id":"70157631","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>b</td>\n","      <td>30.83</td>\n","      <td>0.000</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>w</td>\n","      <td>v</td>\n","      <td>1.25</td>\n","      <td>t</td>\n","      <td>t</td>\n","      <td>1</td>\n","      <td>g</td>\n","      <td>0</td>\n","      <td>+</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>a</td>\n","      <td>58.67</td>\n","      <td>4.460</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>q</td>\n","      <td>h</td>\n","      <td>3.04</td>\n","      <td>t</td>\n","      <td>t</td>\n","      <td>6</td>\n","      <td>g</td>\n","      <td>560</td>\n","      <td>+</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>a</td>\n","      <td>24.50</td>\n","      <td>0.500</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>q</td>\n","      <td>h</td>\n","      <td>1.50</td>\n","      <td>t</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>g</td>\n","      <td>824</td>\n","      <td>+</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>b</td>\n","      <td>27.83</td>\n","      <td>1.540</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>w</td>\n","      <td>v</td>\n","      <td>3.75</td>\n","      <td>t</td>\n","      <td>t</td>\n","      <td>5</td>\n","      <td>g</td>\n","      <td>3</td>\n","      <td>+</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>b</td>\n","      <td>20.17</td>\n","      <td>5.625</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>w</td>\n","      <td>v</td>\n","      <td>1.71</td>\n","      <td>t</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>s</td>\n","      <td>0</td>\n","      <td>+</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  0      1      2  3  4  5  6     7  8  9   10 11   12 13\n","0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  g    0  +\n","1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  g  560  +\n","2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  g  824  +\n","3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  g    3  +\n","4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  s    0  +"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["\n","# Load the dataset\n","cc_apps = pd.read_csv(\"cc_approvals.data\", header=None) \n","cc_apps.head()"]},{"cell_type":"code","execution_count":3,"id":"024d7607","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 690 entries, 0 to 689\n","Data columns (total 14 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   0       690 non-null    object \n"," 1   1       690 non-null    object \n"," 2   2       690 non-null    float64\n"," 3   3       690 non-null    object \n"," 4   4       690 non-null    object \n"," 5   5       690 non-null    object \n"," 6   6       690 non-null    object \n"," 7   7       690 non-null    float64\n"," 8   8       690 non-null    object \n"," 9   9       690 non-null    object \n"," 10  10      690 non-null    int64  \n"," 11  11      690 non-null    object \n"," 12  12      690 non-null    int64  \n"," 13  13      690 non-null    object \n","dtypes: float64(2), int64(2), object(10)\n","memory usage: 75.6+ KB\n"]}],"source":["# Investigating the missing values\n","cc_apps.info()"]},{"cell_type":"markdown","id":"09704e05","metadata":{},"source":["For the follow up action the values in target columns are in the format that must be changed."]},{"cell_type":"code","execution_count":4,"id":"894781ab","metadata":{},"outputs":[],"source":["#converting the target columns values.\n","cc_apps[13] = cc_apps[13].map({'+':1 , '-':0})"]},{"cell_type":"markdown","id":"4379f6ef","metadata":{},"source":["It seems there is no missing value. Taking a deep look in columns, shows the missing values mentioned as \"?\"."]},{"cell_type":"code","execution_count":5,"id":"3a1e7559","metadata":{},"outputs":[{"data":{"text/plain":["0     12\n","1     12\n","5      9\n","6      9\n","3      6\n","4      6\n","2      0\n","7      0\n","8      0\n","9      0\n","10     0\n","11     0\n","12     0\n","13     0\n","dtype: int64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Replacing the question marks with Nan \n","cc_apps.replace('?',np.nan, inplace= True)\n","cc_apps.isna().sum().sort_values(ascending= False)"]},{"cell_type":"markdown","id":"4d8479d7","metadata":{},"source":["As we saw in the dataset, some of the columns in numeric are in object. These such a columns must be changed to numeric."]},{"cell_type":"code","execution_count":6,"id":"cfb54e41","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 690 entries, 0 to 689\n","Data columns (total 14 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   0       678 non-null    object \n"," 1   1       678 non-null    float64\n"," 2   2       690 non-null    float64\n"," 3   3       684 non-null    object \n"," 4   4       684 non-null    object \n"," 5   5       681 non-null    object \n"," 6   6       681 non-null    object \n"," 7   7       690 non-null    float64\n"," 8   8       690 non-null    object \n"," 9   9       690 non-null    object \n"," 10  10      690 non-null    int64  \n"," 11  11      690 non-null    object \n"," 12  12      690 non-null    int64  \n"," 13  13      690 non-null    int64  \n","dtypes: float64(3), int64(3), object(8)\n","memory usage: 75.6+ KB\n"]}],"source":["# converting the numeric columns that are in object format.\n","\n","col_to_convert = [1, 2, 7, 12, 13]\n","cc_apps[col_to_convert] = cc_apps[col_to_convert].apply(pd.to_numeric, errors = 'coerce')\n","cc_apps.info()\n"]},{"cell_type":"markdown","id":"28d2cbde","metadata":{},"source":["Now we need to handling the missing values. Although the number of missing values in the dataset are less than %5 and we can drop all of them, we prefere to impute them."]},{"cell_type":"code","execution_count":7,"id":"9abd08c2","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>b</td>\n","      <td>30.83</td>\n","      <td>0.000</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>w</td>\n","      <td>v</td>\n","      <td>1.25</td>\n","      <td>t</td>\n","      <td>t</td>\n","      <td>1</td>\n","      <td>g</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>a</td>\n","      <td>58.67</td>\n","      <td>4.460</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>q</td>\n","      <td>h</td>\n","      <td>3.04</td>\n","      <td>t</td>\n","      <td>t</td>\n","      <td>6</td>\n","      <td>g</td>\n","      <td>560</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>a</td>\n","      <td>24.50</td>\n","      <td>0.500</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>q</td>\n","      <td>h</td>\n","      <td>1.50</td>\n","      <td>t</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>g</td>\n","      <td>824</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>b</td>\n","      <td>27.83</td>\n","      <td>1.540</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>w</td>\n","      <td>v</td>\n","      <td>3.75</td>\n","      <td>t</td>\n","      <td>t</td>\n","      <td>5</td>\n","      <td>g</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>b</td>\n","      <td>20.17</td>\n","      <td>5.625</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>w</td>\n","      <td>v</td>\n","      <td>1.71</td>\n","      <td>t</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>s</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  0      1      2  3  4  5  6     7  8  9   10 11   12  13\n","0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  g    0   1\n","1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  g  560   1\n","2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  g  824   1\n","3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  g    3   1\n","4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  s    0   1"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["cc_apps.head()"]},{"cell_type":"code","execution_count":8,"id":"3f1a4411","metadata":{},"outputs":[{"data":{"text/plain":["2      0\n","7      0\n","8      0\n","9      0\n","10     0\n","11     0\n","12     0\n","13     0\n","3      6\n","4      6\n","5      9\n","6      9\n","0     12\n","1     12\n","dtype: int64"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["cc_apps.isna().sum().sort_values()"]},{"cell_type":"markdown","id":"dbd339db","metadata":{},"source":["I this step we have to divive the data set into train and test sections. before that we need to categories the data into categorical and numerical data sets. Then we can handling the missing data by applying the imputation from sklearn. Note that for the test part it must be just transform (not fit transform)."]},{"cell_type":"code","execution_count":30,"id":"bb1ae897","metadata":{},"outputs":[],"source":["# divide the data set into train and test\n","X_cat = cc_apps.drop([1, 2, 7, 10, 12, 13], axis=1)\n","X_num = cc_apps.drop([0, 3, 4, 5, 6, 8, 9, 10, 11, 13], axis=1)\n","Y = cc_apps[13]\n","x_cat_train , x_cat_test, y_train, y_test = train_test_split(X_cat, Y, test_size = 0.2, random_state = 100)\n","x_num_train, x_num_test, y_train, y_test = train_test_split(X_num, Y, test_size = 0.2, random_state= 100)\n"]},{"cell_type":"code","execution_count":31,"id":"e9e4bd40","metadata":{},"outputs":[],"source":["# missing values imputation for categorical and numeric data seperately\n","imp_cat = SimpleImputer (strategy = \"most_frequent\")\n","imp_num = SimpleImputer()\n","\n","x_cat_train = imp_cat.fit_transform(x_cat_train)\n","x_cat_test = imp_cat.transform(x_cat_test)\n","\n","x_num_train = imp_num.fit_transform(x_num_train)\n","x_num_test = imp_num.transform(x_num_test)\n","\n","# turning the categorical columns to dummy varaibles using OneHotEncoder\n","encoder = OneHotEncoder(sparse_output = False)\n","encoder.fit(x_cat_train)\n","x_cat_train_encoded = encoder.transform(x_cat_train)\n","x_cat_test_encoded = encoder.transform(x_cat_test)\n"]},{"cell_type":"code","execution_count":38,"id":"171c3a19","metadata":{},"outputs":[],"source":["# concatinating the dumy columns with the numeric culumns\n","x_train = np.append(x_cat_train_encoded , x_num_train, axis = 1)\n","x_test = np.append(x_cat_test_encoded, x_num_test, axis = 1)"]},{"cell_type":"code","execution_count":40,"id":"f77fa44a","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(552, 42)\n","(138, 42)\n","(552,)\n","(138,)\n"]}],"source":["# check the shape\n","print (x_train.shape)\n","print(x_test.shape)\n","print(y_train.shape)\n","print(y_test.shape)"]},{"cell_type":"code","execution_count":48,"id":"c430ab30","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.91      0.76      0.83        78\n","           1       0.74      0.90      0.81        60\n","\n","    accuracy                           0.82       138\n","   macro avg       0.82      0.83      0.82       138\n","weighted avg       0.83      0.82      0.82       138\n","\n","====================================\n","[[59 19]\n"," [ 6 54]]\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\behza\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}],"source":["logreg = LogisticRegression()\n","logreg.fit(x_train, y_train)\n","y_pred = logreg.predict(x_test)\n","print(classification_report(y_test, y_pred))\n","print (\"====================================\")\n","print(confusion_matrix(y_test, y_pred))"]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"editor":"DataCamp Workspace","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":5}
